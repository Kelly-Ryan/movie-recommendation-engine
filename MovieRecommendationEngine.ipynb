{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Rate Movies\n",
    "#### 1. Generate user input to test ML algorithm using provided rateMovies script"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please rate the following movie (1-5 (best), or 0 if not seen): \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import remove\n",
    "from os.path import join, isfile\n",
    "from time import time\n",
    "\n",
    "topMovies = \"\"\"1,Toy Story (1995)\n",
    "780,Independence Day (a.k.a. ID4) (1996)\n",
    "590,Dances with Wolves (1990)\n",
    "1210,Star Wars: Episode VI - Return of the Jedi (1983)\n",
    "648,Mission: Impossible (1996)\n",
    "344,Ace Ventura: Pet Detective (1994)\n",
    "165,Die Hard: With a Vengeance (1995)\n",
    "153,Batman Forever (1995)\n",
    "597,Pretty Woman (1990)\n",
    "1580,Men in Black (1997)\n",
    "231,Dumb & Dumber (1994)\"\"\"\n",
    "\n",
    "parentDir = os.path.abspath('')\n",
    "ratingsFile = join(parentDir, \"personalRatings.txt\")\n",
    "\n",
    "if isfile(ratingsFile):\n",
    "    r = input(\"Looks like you've already rated the movies. Overwrite ratings (y/N)? \")\n",
    "    if r and r[0].lower() == \"y\":\n",
    "        remove(ratingsFile)\n",
    "    else:\n",
    "        sys.exit()\n",
    "\n",
    "prompt = \"Please rate the following movie (1-5 (best), or 0 if not seen): \"\n",
    "print(prompt)\n",
    "\n",
    "now = int(time())\n",
    "n = 0\n",
    "\n",
    "f = open(ratingsFile, 'w')\n",
    "for text in topMovies.split(\"\\n\"):\n",
    "    ls = text.strip().split(\",\")\n",
    "    valid = False\n",
    "    while not valid:\n",
    "        rStr = input(ls[1] + \": \")\n",
    "        r = int(rStr) if rStr.isdigit() else -1\n",
    "        if r < 0 or r > 5:\n",
    "            print(prompt)\n",
    "        else:\n",
    "            valid = True\n",
    "            if r > 0:\n",
    "                f.write(\"0::%s::%d::%d\\n\" % (ls[0], r, now))\n",
    "                n += 1\n",
    "f.close()\n",
    "\n",
    "if n == 0:\n",
    "    print(\"No rating provided!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data\n",
    "#### 1. Create RDDs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.master(\"local\")\\\n",
    "    .appName (\"Movie Recommendation Engine\")\\\n",
    "    .config(\"spark.executor.memory \", \"1.5gb\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "movies_rdd = sc.textFile(\"movielens/medium/movies.dat\")\n",
    "ratings_rdd = sc.textFile(\"movielens/medium/ratings.dat\")\n",
    "personal_ratings_rdd = sc.textFile(\"personalRatings.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Exploration\n",
    "#### 1. Split RDD lines on :: separators\n",
    "#### 2. Convert RDDs to dataframes and set column headings\n",
    "#### 3. Show first 3 rows of new dataframes to confirm correct format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies:\n",
      "+-------+-----------------------+----------------------------+\n",
      "|MovieID|Title                  |Genres                      |\n",
      "+-------+-----------------------+----------------------------+\n",
      "|1      |Toy Story (1995)       |Animation|Children's|Comedy |\n",
      "|2      |Jumanji (1995)         |Adventure|Children's|Fantasy|\n",
      "|3      |Grumpier Old Men (1995)|Comedy|Romance              |\n",
      "+-------+-----------------------+----------------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Ratings:\n",
      "+------+-------+------+---------+\n",
      "|UserID|MovieID|Rating|Timestamp|\n",
      "+------+-------+------+---------+\n",
      "|1     |1193   |5     |978300760|\n",
      "|1     |661    |3     |978302109|\n",
      "|1     |914    |3     |978301968|\n",
      "+------+-------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Personal Ratings:\n",
      "+------+-------+------+----------+\n",
      "|UserID|MovieID|Rating|Timestamp |\n",
      "+------+-------+------+----------+\n",
      "|0     |780    |5     |1633962673|\n",
      "|0     |1210   |3     |1633962673|\n",
      "|0     |648    |4     |1633962673|\n",
      "+------+-------+------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "print(\"Movies:\")\n",
    "movies_rdd = movies_rdd.map(lambda line: line.split(\"::\"))\n",
    "movies_df = movies_rdd.map(lambda line: Row(MovieID=line[0], Title=line[1], Genres=line[2])).toDF()\n",
    "movies_df.show(3, truncate=False)\n",
    "\n",
    "print(\"Ratings:\")\n",
    "ratings_rdd = ratings_rdd.map(lambda line: line.split(\"::\"))\n",
    "ratings_df = ratings_rdd.map(lambda line: Row(UserID=line[0], MovieID=line[1], Rating=line[2], Timestamp=line[3])).toDF()\n",
    "ratings_df.show(3, truncate=False)\n",
    "\n",
    "print(\"Personal Ratings:\")\n",
    "personal_ratings_rdd = personal_ratings_rdd.map(lambda line: line.split(\"::\"))\n",
    "personal_ratings_df = personal_ratings_rdd.map(lambda line: Row(UserID=line[0], MovieID=line[1], Rating=line[2], Timestamp=line[3])).toDF()\n",
    "personal_ratings_df.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Check schemas and convert data types where appropriate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "print(\"Movies\")\n",
    "movies_df.printSchema()\n",
    "print(\"Ratings\")\n",
    "ratings_df.printSchema()\n",
    "print(\"Personal Ratings\")\n",
    "personal_ratings_df.printSchema()\n",
    "\n",
    "movies_df = movies_df.withColumn(\"MovieID\", movies_df[\"MovieID\"].cast(IntegerType()))\n",
    "\n",
    "ratings_df = ratings_df.withColumn(\"UserID\", ratings_df[\"UserID\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"MovieID\", ratings_df[\"MovieID\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"Rating\", ratings_df[\"Rating\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"Timestamp\", ratings_df[\"Timestamp\"].cast(\"bigint\"))\n",
    "\n",
    "personal_ratings_df = personal_ratings_df.withColumn(\"UserID\", personal_ratings_df[\"UserID\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"MovieID\", personal_ratings_df[\"MovieID\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"Rating\", personal_ratings_df[\"Rating\"].cast(FloatType()))\\\n",
    "    .withColumn(\"Timestamp\", personal_ratings_df[\"Timestamp\"].cast(\"bigint\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies\n",
      "root\n",
      " |-- MovieID: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Genres: string (nullable = true)\n",
      "\n",
      "Ratings\n",
      "root\n",
      " |-- UserID: string (nullable = true)\n",
      " |-- MovieID: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      " |-- Timestamp: string (nullable = true)\n",
      "\n",
      "Personal Ratings\n",
      "root\n",
      " |-- UserID: string (nullable = true)\n",
      " |-- MovieID: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      " |-- Timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Pre-Processing\n",
    "#### 1. Removes row with null values in selected columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[UserID: int, MovieID: int, Rating: int, Timestamp: bigint]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.na.drop(\"any\")\n",
    "ratings_df.na.drop(subset=[\"UserID\", \"MovieID\", \"Rating\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Convert unix timestamp data to date/time format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import from_unixtime\n",
    "\n",
    "ratings_df = ratings_df.withColumn(\"Timestamp\", from_unixtime(col(\"Timestamp\"), \"dd-MM-yyyy HH:mm:ss\"))\n",
    "ratings_df = ratings_df.withColumnRenamed(\"Timestamp\", \"Date\")\n",
    "\n",
    "personal_ratings_df = personal_ratings_df.withColumn(\"Timestamp\", from_unixtime(col(\"Timestamp\"), \"dd-MM-yyyy HH:mm:ss\"))\n",
    "personal_ratings_df = personal_ratings_df.withColumnRenamed(\"Timestamp\", \"Date\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Add current user ratings to main ratings file\n",
    "#### 4. Join movies to ratings file to show titles and genres"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[MovieID: int, UserID: int, Rating: float, Date: string, Title: string, Genres: string]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add personal ratings from user input to existing ratings\n",
    "ratings_df = personal_ratings_df.union(ratings_df)\n",
    "\n",
    "# join ratings dataframe to movies dataframe\n",
    "movie_ratings_df = ratings_df.join(movies_df, [\"MovieID\"])\n",
    "movie_ratings_df.drop(movies_df.MovieID)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Standardisation\n",
    "#### 1.  Normalise data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-------------------+--------------------+------+\n",
      "|MovieID|UserID|Rating|               Date|               Title|Genres|\n",
      "+-------+------+------+-------------------+--------------------+------+\n",
      "|    148|    53|   1.0|28-12-2000 07:17:06|Awfully Big Adven...| Drama|\n",
      "|    148|   216|   0.4|15-12-2000 08:53:59|Awfully Big Adven...| Drama|\n",
      "|    148|   424|   0.8|18-07-2002 15:40:24|Awfully Big Adven...| Drama|\n",
      "|    148|   482|   0.4|07-12-2000 20:12:34|Awfully Big Adven...| Drama|\n",
      "|    148|   673|   1.0|30-11-2000 21:47:04|Awfully Big Adven...| Drama|\n",
      "|    148|   752|   0.8|14-08-2002 08:12:15|Awfully Big Adven...| Drama|\n",
      "|    148|   840|   0.2|08-12-2000 17:08:58|Awfully Big Adven...| Drama|\n",
      "|    148|  1069|   0.4|23-11-2000 02:05:35|Awfully Big Adven...| Drama|\n",
      "|    148|  1150|   0.4|22-11-2000 06:38:26|Awfully Big Adven...| Drama|\n",
      "|    148|  1242|   0.6|22-11-2000 16:19:36|Awfully Big Adven...| Drama|\n",
      "|    148|  1605|   0.4|22-11-2000 21:57:01|Awfully Big Adven...| Drama|\n",
      "|    148|  2383|   0.4|16-11-2000 23:34:14|Awfully Big Adven...| Drama|\n",
      "|    148|  2456|   0.4|14-11-2000 05:16:33|Awfully Big Adven...| Drama|\n",
      "|    148|  2507|   0.8|13-11-2000 02:31:57|Awfully Big Adven...| Drama|\n",
      "|    148|  3053|   0.6|28-09-2000 20:41:30|Awfully Big Adven...| Drama|\n",
      "|    148|  3184|   0.8|11-09-2000 22:49:13|Awfully Big Adven...| Drama|\n",
      "|    148|  3539|   0.6|22-08-2000 09:20:08|Awfully Big Adven...| Drama|\n",
      "|    148|  3829|   0.4|10-08-2000 21:42:50|Awfully Big Adven...| Drama|\n",
      "|    148|  4169|   0.6|12-12-2000 02:33:22|Awfully Big Adven...| Drama|\n",
      "|    148|  4227|   0.4|07-08-2000 15:48:44|Awfully Big Adven...| Drama|\n",
      "+-------+------+------+-------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Divide all ratings values by 5 so each is a value between 0 and 1\n",
    "movie_ratings_df = movie_ratings_df.withColumn(\"Rating\", col(\"Rating\")/5)\n",
    "movie_ratings_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Alternating Least Squares Algorithm\n",
    "#### 1. Create Training and Testing Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 600559, test: 399659\n",
      "\n",
      "+-------+------+------+-------------------+--------------------+------+\n",
      "|MovieID|UserID|Rating|               Date|               Title|Genres|\n",
      "+-------+------+------+-------------------+--------------------+------+\n",
      "|    148|   424|   0.8|18-07-2002 15:40:24|Awfully Big Adven...| Drama|\n",
      "|    148|   482|   0.4|07-12-2000 20:12:34|Awfully Big Adven...| Drama|\n",
      "|    148|   752|   0.8|14-08-2002 08:12:15|Awfully Big Adven...| Drama|\n",
      "+-------+------+------+-------------------+--------------------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------+------+------+-------------------+--------------------+------+\n",
      "|MovieID|UserID|Rating|               Date|               Title|Genres|\n",
      "+-------+------+------+-------------------+--------------------+------+\n",
      "|    148|    53|   1.0|28-12-2000 07:17:06|Awfully Big Adven...| Drama|\n",
      "|    148|   216|   0.4|15-12-2000 08:53:59|Awfully Big Adven...| Drama|\n",
      "|    148|   673|   1.0|30-11-2000 21:47:04|Awfully Big Adven...| Drama|\n",
      "+-------+------+------+-------------------+--------------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create training and test datasets\n",
    "(training_data_df, test_data_df) = movie_ratings_df.randomSplit([0.6, 0.4], seed=1234)\n",
    "\n",
    "print('Training: {0}, test: {1}\\n'.format(training_data_df.count(), test_data_df.count()))\n",
    "training_data_df.show(3)\n",
    "test_data_df.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Build and train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Root Mean Squared Error: 0.20614037522156928\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Create ALS and set parameters\n",
    "als = ALS(maxIter=20, regParam=0.1, userCol=\"UserID\", itemCol=\"MovieID\", ratingCol=\"Rating\",coldStartStrategy=\"drop\",\n",
    "          implicitPrefs=False, nonnegative=True, rank=2)\n",
    "\n",
    "# train the model using training dataset\n",
    "model = als.fit(training_data_df)\n",
    "\n",
    "#test the model using the training dataset\n",
    "predictions = model.transform(training_data_df)\n",
    "regression_eval = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = regression_eval.evaluate(predictions)\n",
    "print(\"Training - Root Mean Squared Error: {}\".format(str(rmse)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Test model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing - Root Mean Squared Error: 0.20825857531182482\n"
     ]
    }
   ],
   "source": [
    "#test the model using the test dataset\n",
    "predictions = model.transform(test_data_df)\n",
    "regression_eval = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = regression_eval.evaluate(predictions)\n",
    "print(\"Testing - Root Mean Squared Error: {}\".format(str(rmse)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Generate predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|UserID|     recommendations|\n",
      "+------+--------------------+\n",
      "|     0|[{3382, 1.5766106...|\n",
      "+------+--------------------+\n",
      "\n",
      "Movies recommended For you:\n",
      "1. Hour of the Pig, The (1993)\n",
      "2. Foreign Student (1994)\n",
      "3. Song of Freedom (1936)\n",
      "4. JLG/JLG - autoportrait de d�cembre (1994)\n",
      "5. Mamma Roma (1962)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# generate predictions for user 0\n",
    "user = personal_ratings_df.select(als.getUserCol()).distinct().sort(\"UserID\", ascending=True).limit(1)\n",
    "personal_recommendations = model.recommendForUserSubset(user, 5)\n",
    "personal_recommendations.show()\n",
    "\n",
    "output = personal_recommendations.select(col(\"UserID\"),explode(col(\"recommendations\")).alias(\"recommendations\"))\n",
    "output = output.withColumn(\"recommendations\", output[\"recommendations\"].getItem(\"MovieID\")).drop(\"UserID\")\n",
    "output = output.join(movies_df, output.recommendations == movies_df.MovieID, \"inner\").select(movies_df.Title)\n",
    "\n",
    "output_list = output.collect()\n",
    "\n",
    "print(\"Movies recommended For you:\")\n",
    "i = 1\n",
    "for movie in output_list:\n",
    "    print(\"{i}. {movie}\".format(i = i, movie = movie.Title))\n",
    "    i = i +1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}